# -*- coding: utf-8 -*-
"""CNN_Malware.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16RYfueq390bkeW2RRSqYte5fwS4hwXNp
"""

!gdown --id 170-6j9q2YmCT7tmwo8tgP3D0jjH489lA

!unzip output.zip
!mv /content/content/output.csv /content/output.csv

import numpy as np
import pandas as pd

def clean_dataset(df):
    assert isinstance(df, pd.DataFrame), "df needs to be a pd.DataFrame"
    df.dropna(inplace=True)
    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)
    return df[indices_to_keep]

def y_labels(data):
    dict={'Adware':0,'Banker':1 , 'FileInfector':2,'PUA':3,'Riskware':4,'SMS':5,'Trojan':6,'Backdoor':7,'Dropper':8,'NoCategory':9,'Ransomware':10, 'Scareware':11 ,'Spy':12 ,'Zeroday':13,'Benign':14}
    for key, value in dict.items():
      data[data[9505]==key]=value
    return data

def reduce_size_float(data):
  for col in data.columns:
    data[col] = data[col].astype(np.float16)
  return data

best_features=[]
myFile = open("best_features.txt", "r")
for myLine in myFile:
  try:
    best_features.append(int(myLine))
  except:
    continue

best_features.sort()

best_features.remove(9501)

best_features.remove(9502)

float_cols=[9501,9502]

X_Data=pd.read_csv("/content/output.csv",header=None,dtype=np.uint16,usecols=best_features)
print(1)
data_2=pd.read_csv("/content/output.csv",header=None,usecols=float_cols)
print(2)
X_Data=clean_dataset(X_Data.iloc[1:,:])
print(3)
data_2=clean_dataset(data_2.iloc[1:,:])
print(4)

data_2=reduce_size_float(data_2)
print(5)

X_Data=pd.concat([X_Data,data_2],axis=1)
del data_2
print(6)

y=pd.read_csv("/content/output.csv",usecols=[9505],header=None)
y.iloc[1:,:].head()

y_data=y_labels(y.iloc[1:,:])

y_data.head()

X_Data.shape

y_data.shape

from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.callbacks import EarlyStopping,Callback
from time import time
from sklearn import metrics
import tensorflow as tf

def Image_Creation(X_Data_Best):
    print("Image Creation")
    i = 0
    X_Data_Final = []
    while i < len(X_Data_Best):
        X = X_Data_Best.iloc[i]
        X = X[:-224].reshape(32, 32).astype(np.uint8)
        X_Data_Final.append(X)
        i = i + 1
    return X_Data_Final

X_Data_Final = Image_Creation(X_Data)

def Label_Encoding(Y_Data):
    print("Label Encoding")
    Y_Data_Final = Y_Data
    le = LabelEncoder()
    le.fit(Y_Data_Final)
    list(le.classes_)
    Y_Data_Final = le.transform(Y_Data_Final)
    Y_Data_Final = np.reshape(Y_Data_Final, (-1, 1))
    return Y_Data_Final

Y_Data_Final = Label_Encoding(y.iloc[1:,:])

np.unique(Y_Data_Final)

from google.colab import drive
drive.mount('/content/drive')

def MyModel(X_Data_Final, Y_Data_Final):
    print("Model")

    start = time()

    epochs = 30
    optimizer = 'adam'
    np.random.seed(9)

    X_tr, X_te, Y_tr, Y_te = train_test_split(X_Data_Final, Y_Data_Final, test_size=0.20, random_state=42)
    X_tr = np.array(X_tr).reshape(-1, 32, 32, 1)
    X_te = np.array(X_te).reshape(-1, 32, 32, 1)
    early_stopping_monitor = EarlyStopping(patience=3)

    print(X_tr.shape, X_te.shape,Y_tr.shape,Y_te.shape)
    model_2 = Sequential()
    model_2.add(Conv2D(32, (3, 3), activation='relu', input_shape=X_tr.shape[1:]))
    model_2.add(Conv2D(64, (3, 3), activation='relu'))
    model_2.add(MaxPooling2D(pool_size=(2, 2)))
    model_2.add(Flatten())
    model_2.add(Dense(256, activation='relu'))
    model_2.add(Dense(15, activation='softmax'))
    model_2.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath="/content/drive/MyDrive/grad/CNN-2.hdf5", 
                               verbose=1, 
                               save_best_only=True
                              )
    filename='/content/drive/MyDrive/grad/log-2.csv'
    history_logger=tf.keras.callbacks.CSVLogger(filename, separator=",", append=True)
    
    callbackslist=[early_stopping_monitor,checkpointer,history_logger,]
    history = model_2.fit(X_tr, Y_tr, validation_data=(X_te, Y_te), epochs=epochs, callbacks=callbackslist , batch_size=32, verbose=1)
    print(time()-start)
    print(history.history.keys())
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')
    plt.show()
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model Loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')
    plt.show()

MyModel(X_Data_Final,Y_Data_Final)