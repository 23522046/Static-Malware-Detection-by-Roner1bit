# -*- coding: utf-8 -*-
"""TestForLSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F9LjSYV9yD77C6mBezcs6FHkIPLpNM5s
"""

import numpy
import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.callbacks import EarlyStopping,Callback

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, RNN, LSTM, GRU, Bidirectional, Embedding, Dropout
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from tensorflow.keras.callbacks import EarlyStopping

!gdown --id 1-O4uzkbAvvSuuE88HQPkVFU1hfaPEFep

!gdown --id 1-IMWETCjw1Vxi4beBuHo8I-h-zUP6gmT

X_Data=pd.read_csv("/content/Features.csv")
y_data=pd.read_csv("/content/Label.csv")

def reduce_size_float(data):
  for col in data.columns:
    data[col] = data[col].astype(np.int16)
  return data

X_Data = reduce_size_float(X_Data)

from sklearn.model_selection import train_test_split
X_tr, X_te, Y_tr, Y_te = train_test_split(X_Data, y_data, test_size=0.40, random_state=42)

X_tr = X_tr.iloc[: , 1:]
X_te = X_te.iloc[: , 1:]
Y_tr = Y_tr.iloc[: , 1:]
Y_te = Y_te.iloc[: , 1:]

print(X_tr.shape, X_te.shape,Y_tr.shape,Y_te.shape)

def LSTM_model():
    
    model = Sequential()    
    model.add(LSTM(units = 1024, activation='relu', return_sequences = True, input_shape = (X_tr.shape[1],1)))
    
    model.add(LSTM(units = 1024, activation='relu', return_sequences = True))
    
    model.add(LSTM(units = 1024, activation='relu', return_sequences = True))

    model.add(LSTM(units = 1024, activation='relu'))

    model.add(Dense(units=1, activation='softmax'))
    
    return model

from keras import backend as K
import tensorflow as tf
model = LSTM_model()
model.summary()


model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), metrics=['accuracy'])

import tensorflow.keras.backend as K
X_tr = K.constant(X_tr)
X_te = K.constant(X_te)

epochs = 1500
early_stopping_monitor = EarlyStopping(patience=3)

history = model.fit(X_tr, Y_tr, validation_data=(X_te, Y_te), epochs=epochs, callbacks=[early_stopping_monitor],
                          batch_size=32)